#!/usr/bin/env python
__author__    = 'Hoby Rakotoarivelo'
__license__   = 'GPL v3'
__version__   = '1.0'
__copyright__ = 'Copyright 2016, The trinity project'

import os
import sys
import time
import optparse
import subprocess

#
def compact_benchmark_data(param):

    testcase = param.name
    nb_cores = int(param.cores)
    nb_field = int(param.fields)

    # for each kernel
    for k in range(1,5):
        target = 'results/benchs/'+testcase+'_'+str(k)+'.dat'
        # skip if already exists
        if os.path.exists(target):
            continue

        with open(target,'w') as output:
            prefix = 'results/_'+str(k)+'/'+testcase+'_w_'
            for rank in range(nb_cores):
                path = prefix + str(rank+1).rjust(2,'0')+'.dat'
                # skip if file does not exist
                if not os.path.exists(path):
                    continue

                count = 0
                stats = [0] * nb_field
                with open(path,'r') as f:
                    for line in f:
                        values = line.split()
                        for i in range(nb_field):
                            stats[i] += int(values[i])
                        count += 1

                assert(count > 0)
                for i in range(nb_field):
                    stats[i] /= count
                    output.write('{:01d}'.format(int(stats[i]))+'\t')
                output.write('\n')
        #
        print('>> '+target+'')

#
def generate_gnuplot_script(param):

    testcase = param.name
    nb_cores = int(param.cores)

    data  = 'benchs/'+testcase    # data path
    index = 4
    stats = [''] * 4
    t_seq = [''] * 4
    color = [''] * 4

    for i in range(0,4):
        stats[i] = 'results/'+data+'_'+str(i+1)+'.dat'
        assert(os.path.exists(stats[i]))
        with open(stats[i],'r') as f:
            line = f.readline().split()
            t_seq[i] = line[index]
            #print('>> t_seq['+str(i+1)+'] = '+str(t_seq[i]))

        assert(int(t_seq[i]) > 0)

    color[0] = '#4682B4'
    color[1] = '#778899'
    color[2] = '#000050'
    color[3] = '#800080'

    s  = '# ---------------------------------\n'
    s += '# '+testcase+'.gnuplot\n'
    s += '# generated by trigen '+time.strftime('%c')+'\n'
    s += '# (c) 2016 H. Rakotoarivelo\n'
    s += '# ---------------------------------\n'
    s += 'reset\n'
    s += 'set terminal postscript eps enhanced color 14 size 6.5cm,6.5cm\n'
    s += 'set output "../'+testcase+'_runtime.eps"\n'
    s += 'set size ratio 1\n'
    s += 'set xlabel "cores"\n'
    s += 'set ylabel "elapsed time (s)"\n'
    s += 'set format y "%.0f"\n'
    s += 'set logscale x 2\n'
    s += 'set grid\n'
    s += 'plot "'+testcase+'_1.dat" using 1:($5/1e3) with linespoint title "refinement"  '
    s += 'lc rgb "'+color[0]+'" pt 5,\\\n'
    s += '     "'+testcase+'_2.dat" using 1:($5/1e3) with linespoint title "contraction" '
    s += 'lc rgb "'+color[1]+'" pt 3,\\\n'
    s += '     "'+testcase+'_3.dat" using 1:($5/1e3) with linespoint title "swapping"    '
    s += 'lc rgb "'+color[2]+'" pt 3,\\\n'
    s += '     "'+testcase+'_4.dat" using 1:($5/(3*1e3)) with linespoint title "smoothing (x3)"   '
    s += 'lc rgb "'+color[3]+'" pt 1\n'
    s += '# ---------------------------------\n'
    s += '\n'
    s += 'reset\n'
    s += 'set terminal postscript eps enhanced color 14 size 6.5cm,6.5cm\n'
    s += 'set output "../'+testcase+'_speedup.eps"\n'
    s += 'set size ratio 1\n'
    s += 'unset logscale x\n'
    s += 'set key left\n'
    s += 'set ylabel "speedup"\n'
    s += 'set xlabel "cores"\n'
    s += 'set yrange [1:'+str(nb_cores)+']\n'
    s += 'set ytics '+str(int(nb_cores/8))+'\n'
    s += '\n'
    s += 't1 = '+t_seq[0]+'\n'
    s += 't2 = '+t_seq[1]+'\n'
    s += 't3 = '+t_seq[2]+'\n'
    s += 't4 = '+t_seq[3]+'\n'
    s += '\n'
    s += 'set style data histogram\n'
    s += 'set style fill solid border\n'
    s += 'set style histogram clustered\n'
    s += 'set grid\n'
    s += '# ---------------------------------\n'
    s += 'plot "'+testcase+'_1.dat" using (t1/$5):xticlabels(1) title "refinement"  '
    s += ' lc rgb "'+color[0]+'",\\\n'
    s += '     "'+testcase+'_2.dat" using (t2/$5):xticlabels(1) title "contraction" '
    s += ' lc rgb "'+color[1]+'",\\\n'
    s += '     "'+testcase+'_3.dat" using (t3/$5):xticlabels(1) title "swapping"    '
    s += ' lc rgb "'+color[2]+'",\\\n'
    s += '     "'+testcase+'_4.dat" using (t4/$5):xticlabels(1) title "smoothing"   '
    s += ' lc rgb "'+color[3]+'"\n'
    s += '# ---------------------------------'

    # a) store to file
    script = testcase+'.gnuplot'
    path = 'results/benchs/'+script
    print('>> '+path)
    with open(path,'w') as output:
        output.write(s)

    # b) execute gnuplot script
    print('>> cd results/benchs')
    os.chdir('results/benchs')
    print('>> gnuplot '+script)
    subprocess.call(['gnuplot', script])

    print('>> results/'+testcase+'_runtime.eps')
    print('>> results/'+testcase+'_speedup.eps')

#
def clean_data(param):

    testcase = param.name
    nb_cores = int(param.cores)
    eps = [''] * 2

    for k in range(1,5):
        #
        prefix = 'results/_'+str(k)+'/'+testcase+"_w_"
        for rank in range(nb_cores):
            path = prefix + str(rank+1).rjust(2,'0')+'.dat'
            # skip if file does not exist
            if os.path.exists(path):
                print('>> rm '+path)
                os.remove(path)
        #
        data = 'results/benchs/'+testcase+'_'+str(k)+'.dat'
        if os.path.exists(data):
            print('>> rm '+data)
            os.remove(data)

    #
    script = 'results/benchs/'+testcase+'.gnuplot'
    eps[0] = 'results/'+testcase+'_runtime.eps'
    eps[1] = 'results/'+testcase+'_speedup.eps'
    if os.path.exists(script):
        print('>> rm '+script)
        os.remove(script)

    for i in range(0,2):
        if os.path.exists(eps[i]):
            print('>> rm '+eps[i])
            os.remove(eps[i])

    sys.exit(0)


# sum over the 3 architectures
def reduce_knl_stats(param):

    testcase = param.name
    nb_cores = int(param.cores)
    nb_field = 7
    nb_runs  = 7
    out = ['']*3

    #
    stats = [[]]
    run = ['']*3
    run[0] = 'knl'
    run[1] = 'hyp'
    run[2] = 'llc'

    for mode in range(3):
        # flush
        stats = [[0 for y in range(nb_field)] for x in range(nb_cores)]
        # set output path
        out[mode] = 'results/benchs/'+testcase+'_'+run[mode]+'_reduc.dat'
        # reduce over kernels
        for k in range(4):
            data = 'results/benchs/'+testcase+'_'+run[mode]+'_'+str(k+1)+'.dat'
            assert(os.path.exists(data))
            with open(data,'r') as f:
                c = 0
                for line in f:
                    values = line.split()
                    for i in range(nb_field):
                        stats[c][i] += int(values[i])
                    c = c+1
                assert(c == nb_runs)

        # write to file
        with open(out[mode],'w') as f:
            for r in range(nb_runs):
                for i in range(nb_field):
                    if i == 0:
                        stats[r][i] /= 4
                    f.write('{:01d}'.format(int(stats[r][i]))+'\t')
                f.write('\n')

# sum over the 3 architectures
def reduce_hasw_stats(param):

    testcase = param.name
    nb_cores = int(param.cores)
    nb_field = 7
    nb_runs  = 6
    out = ['']*3

    #
    stats = [[]]
    run = ['']*3
    run[0] = 'nor'
    run[1] = 'hyp'

    for mode in range(2):
        # flush
        stats = [[0 for y in range(nb_field)] for x in range(nb_cores)]
        # set output path
        out[mode] = 'results/benchs/'+testcase+'_'+run[mode]+'_reduc.dat'
        # reduce over kernels
        for k in range(4):
            data = 'results/benchs/'+testcase+'_'+run[mode]+'_'+str(k+1)+'.dat'
            assert(os.path.exists(data))
            with open(data,'r') as f:
                c = 0
                for line in f:
                    values = line.split()
                    for i in range(nb_field):
                        stats[c][i] += int(values[i])
                    c = c+1
                assert(c == nb_runs)

        # write to file
        with open(out[mode],'w') as f:
            for r in range(nb_runs):
                for i in range(nb_field):
                    if i == 0:
                        stats[r][i] /= 4
                    f.write('{:01d}'.format(int(stats[r][i]))+'\t')
                f.write('\n')

# sum over the 3 architectures
def reduce_neha_stats(param):

    testcase = param.name
    nb_cores = int(param.cores)
    nb_field = 7
    nb_runs  = 4

    #
    stats = [[]]

    # flush
    stats = [[0 for y in range(nb_field)] for x in range(nb_cores)]
    # set output path
    out = 'results/benchs/'+testcase+'_reduc.dat'
    # reduce over kernels
    for k in range(4):
        data = 'results/benchs/'+testcase+'_'+str(k+1)+'.dat'
        assert(os.path.exists(data))
        with open(data,'r') as f:
            c = 0
            for line in f:
                values = line.split()
                for i in range(nb_field):
                    stats[c][i] += int(values[i])
                c = c+1
            assert(c == nb_runs)

    # write to file
    with open(out,'w') as f:
        for r in range(nb_runs):
            for i in range(nb_field):
                if i == 0:
                    stats[r][i] /= 4
                f.write('{:01d}'.format(int(stats[r][i]))+'\t')
            f.write('\n')

#
if __name__ == '__main__':

    parser = optparse.OptionParser()
    parser.add_option('-n', dest='name'  , default='test',help='run/testcase name')
    parser.add_option('-p', dest='cores' , default=4     ,help='number of cores')
    parser.add_option('-f', dest='fields', default=25    ,help='number of fields')
    parser.add_option('-g', dest='gplot', action='store_true',help='generate gnuplot script')
    parser.add_option('-c', dest='clean', action='store_true',help='clean benchmark data')

    # retrieve and check params
    (param,args) = parser.parse_args()

    # remove data
    #if(param.clean):
    #    clean_data(param)

    # compact data
    #compact_benchmark_data(param)

    # create gnuplot file
    #if(param.gplot):
    #    generate_gnuplot_script(param)

    reduce_neha_stats(param)

